{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDhcfuPUpb-d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "# import wandb\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers import Add, LeakyReLU\n",
        "from keras import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO-U4wl1p_eo"
      },
      "source": [
        "# **Handle Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TzeIPOIp-CU"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load(target_path, input_path):\n",
        "  # Read and decode an image file to a uint8 tensor\n",
        "  real_image = tf.io.read_file((target_path))\n",
        "  real_images = tf.image.decode_jpeg(real_image, channels= 3)\n",
        "  input_image = tf.io.read_file((input_path))\n",
        "  input_images = tf.image.decode_jpeg(input_image, channels= 3)\n",
        "\n",
        "  # Convert both images to float32 tensors\n",
        " \n",
        "  # input_image, real_image = resize(input_image, real_image, height=256, width=256)\n",
        "  return input_images, real_images\n",
        "\n",
        "\n",
        "def resize(input_image, real_image, height=256, width=256):\n",
        "  input_image = tf.image.resize(input_image, (height, width), method= 'bilinear')\n",
        "  real_image = tf.image.resize(real_image, (height, width), method= 'bilinear')\n",
        "  return input_image, real_image\n",
        "\n",
        "\n",
        "def normalize(input_image, real_image):\n",
        "  input_image = tf.cast(input_image, tf.float32)\n",
        "  real_image = tf.cast(real_image, tf.float32)\n",
        "  input_image = (input_image / 127.5) - 1\n",
        "  real_image = (real_image / 127.5) - 1\n",
        "\n",
        "  return input_image, real_image\n",
        "\n",
        "def load_images_train(target_path, input_path):\n",
        "  input_image, real_image = load(target_path, input_path)\n",
        "#   input_image, real_image = random_jitter(input_image, real_image)\n",
        "  input_image, real_image = normalize(input_image, real_image)\n",
        "  input_image, real_image = resize(input_image, real_image)\n",
        "  return input_image, real_image\n",
        "\n",
        "\n",
        "def load_images_test(target_path, input_path):\n",
        "  input_image, real_image = load(target_path, input_path)\n",
        "  input_image, real_image = normalize(input_image, real_image)\n",
        "  input_image, real_image = resize(input_image, real_image)\n",
        "  return input_image, real_image\n",
        "\n",
        "\n",
        "def generate_images(model, test_input, tar):\n",
        "  prediction = model(test_input, training=True)\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  display_list = [test_input[0]*0.5 + 0.5, tar[0]*0.5 + 0.5, prediction[0]*0.5 + 0.5]\n",
        "  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "\n",
        "  for i in range(3):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    plt.title(title[i])\n",
        "    # Getting the pixel values in the [0, 1] range to plot.\n",
        "    plt.imshow(display_list[i])\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po85PNwKqJmb"
      },
      "source": [
        "# **Data Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9oMXGr4qHSy"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 500\n",
        "\n",
        "target_path_train= r\"\" \n",
        "input_path_train= r\"\"\n",
        "target_path_test= r\"\"\n",
        "input_path_test=  r\"\"\n",
        "\n",
        "train_image = []\n",
        "train_target = []\n",
        "tu = False\n",
        "for name_target in os.listdir(target_path_train):\n",
        "  if tu:\n",
        "    break\n",
        "  for name_image in os.listdir(input_path_train):\n",
        "    if name_image == name_target.split('.')[0].split('_')[0] + '.png':\n",
        "      train_image.append(input_path_train + '/{}'.format(name_image))\n",
        "      train_target.append(target_path_train + '/{}'.format(name_target))\n",
        "#       if len(train_target)==200:\n",
        "#         tu=True\n",
        "#         break\n",
        "\n",
        "test_image = []\n",
        "test_target = []\n",
        "op = False\n",
        "for name_target in os.listdir(target_path_test):\n",
        "  if op:\n",
        "    break\n",
        "  for name_image in os.listdir(input_path_test):\n",
        "    if name_image == name_target.split('.')[0].split('_')[0] + '.png':\n",
        "      test_image.append(input_path_test + '/{}'.format(name_image))\n",
        "      test_target.append(target_path_test + '/{}'.format(name_target))\n",
        "#       if len(test_target)==1:\n",
        "#         op= True\n",
        "#         break\n",
        "\n",
        "train_datasets = tf.data.Dataset.from_tensor_slices((train_image, train_target )).map(load_images_train, num_parallel_calls= tf.data.experimental.AUTOTUNE).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_datasets = tf.data.Dataset.from_tensor_slices((test_image, test_target )).map(load_images_test, num_parallel_calls= tf.data.experimental.AUTOTUNE).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twmnYRiSqYkW"
      },
      "source": [
        "# **Check Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpEDR_EZqTt-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize= (20, 20))\n",
        "for image, mask in train_datasets.take(1):\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.imshow(image[0]*0.5 + 0.5)\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.imshow(mask[0]*0.5 + 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6ZabibAqj_H"
      },
      "source": [
        "# **Generator**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEoYX4IjqgGT"
      },
      "outputs": [],
      "source": [
        "class spatial_attention(tf.keras.layers.Layer):\n",
        "    \"\"\" spatial attention module \n",
        "        \n",
        "    Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n",
        "    As described in https://arxiv.org/abs/1807.06521.\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel_size=7, trainable=True ,**kwargs):\n",
        "        self.kernel_size = kernel_size\n",
        "        super(spatial_attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.conv3d = tf.keras.layers.Conv2D(filters=1, \n",
        "                                             kernel_size=self.kernel_size,\n",
        "                                             strides=1, \n",
        "                                             padding='same', \n",
        "                                             activation='sigmoid',\n",
        "                                             kernel_initializer='he_normal', \n",
        "                                             use_bias=False)\n",
        "        super(spatial_attention, self).build(input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "    def call(self, inputs):\n",
        "        avg_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x, axis=-1, keepdims=True))(inputs)\n",
        "        max_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.max(x, axis=-1, keepdims=True))(inputs)\n",
        "        concat = tf.keras.layers.Concatenate(axis=-1)([avg_pool, max_pool])\n",
        "        feature = self.conv3d(concat)\t\n",
        "        multiplied = tf.keras.layers.Multiply()([inputs, feature])\n",
        "        # shape_out = multiplied.shape   \n",
        "        # return tf.keras.layers.multiply()([inputs, feature])\n",
        "        return multiplied\n",
        "    \n",
        "\n",
        "class Attention_map(tf.keras.layers.Layer):\n",
        "    \"\"\" \n",
        "    Attention module\n",
        "    As described in: https://arxiv.org/pdf/2112.01098.pdf\n",
        "    \"\"\" \n",
        "    def __init__(self,num_filters, trainable=True, **kwargs):\n",
        "        self.num_filters = num_filters\n",
        "        self.initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "        self.conv4a = tf.keras.layers.Conv2D(4*self.num_filters, \n",
        "                                            kernel_size=3,\n",
        "                                            padding=\"same\")\n",
        "        \n",
        "        self.conv8 = tf.keras.layers.Conv2D(8*self.num_filters, \n",
        "                                            kernel_size=3,\n",
        "                                            padding=\"same\")\n",
        "        \n",
        "        self.conv4b = tf.keras.layers.Conv2D(4*self.num_filters, \n",
        "                                            kernel_size=3,\n",
        "                                            padding=\"same\")\n",
        "        \n",
        "        self.conv2 = tf.keras.layers.Conv2D(2*self.num_filters, \n",
        "                                            kernel_size=3,\n",
        "                                            padding=\"same\") \n",
        "        \n",
        "        super(Attention_map,self).__init__(**kwargs)\n",
        "    \n",
        "    def call(self, inputs, training, **kwargs):\n",
        "        x = self.conv4a(inputs)\n",
        "        x = self.conv8(x)\n",
        "        x = self.conv4b(x)\n",
        "        x = self.conv2(x)\n",
        "        return x\n",
        "    \n",
        "\n",
        "def compute_fused(fenc, fdec, name_layer, trainable=True):\n",
        "    \"\"\"\n",
        "    Compute fused module \\n\n",
        "    f_fused = fenc*Attention_map[0] + fdec*Attention_map[1]\n",
        "    \"\"\"\n",
        "    fconcat =  tf.concat([fenc, fdec], 0)\n",
        "    output_attentionmap = Attention_map(num_filters=64,trainable=trainable, name=name_layer)(fconcat)\n",
        "    f_fused = fenc*output_attentionmap[0] + fdec*output_attentionmap[1]\n",
        "    return f_fused"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSsg88Xcqpq0"
      },
      "outputs": [],
      "source": [
        "class Residual_Block(keras.layers.Layer):\n",
        "    \"\"\" \n",
        "    Residual Block from ResNet:\n",
        "    Input: (2H,2W,C) => Ouput: (H,W,C')\n",
        "    \"\"\"\n",
        "    def __init__(self, num_filter, kernel_size=3, trainable=True,  **kwargs):\n",
        "        super(Residual_Block, self).__init__(**kwargs)\n",
        "        self.filters= num_filter\n",
        "        self.kernel_size = kernel_size\n",
        "        self.trainable = trainable\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.x_skip = tf.keras.layers.Conv2D(self.filters, \n",
        "                                             kernel_size=1, \n",
        "                                             padding=\"same\")\n",
        "\n",
        "        self.conv2a = tf.keras.layers.Conv2D(self.filters, \n",
        "                                             kernel_size=self.kernel_size, \n",
        "                                             padding='same')\n",
        "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.conv2b = tf.keras.layers.Conv2D(filters=self.filters, \n",
        "                                             kernel_size=self.kernel_size,\n",
        "                                             padding='same')\n",
        "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
        "        super(Residual_Block, self).build(input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        x_skip = self.conv2a(inputs)\n",
        "\n",
        "        x = self.conv2a(inputs)\n",
        "        x = self.bn2a(x,self.trainable)\n",
        "        out1 = tf.nn.relu(x)\n",
        "\n",
        "        out2 = self.conv2b(out1)\n",
        "        out2 = self.bn2b(out2,self.trainable)\n",
        "        out2 = tf.nn.relu(out2)\n",
        "\n",
        "\n",
        "        add = tf.keras.layers.Add()([x_skip, out2])\n",
        "        out = tf.nn.relu(add)\n",
        "        return out\n",
        "    \n",
        "\n",
        "class Decoder_Block(tf.keras.layers.Layer):\n",
        "    \"\"\" \n",
        "    Decoder Block: Upsampling and Residual Block \n",
        "    Input: (H,W, 2C) => Ouput: (2H,2W, C)\n",
        "    \"\"\"\n",
        "    def __init__(self,num_filter, kernel_size=3, trainable=True, **kwargs):\n",
        "        super(Decoder_Block, self).__init__(**kwargs)\n",
        "        self.num_filter = num_filter\n",
        "        self.kernel_size = kernel_size\n",
        "        self.residual = Residual_Block(num_filter=self.num_filter, \n",
        "                                       kernel_size=self.kernel_size)\n",
        "        self.upsampling = tf.keras.layers.Conv2DTranspose(filters=self.num_filter,\n",
        "                                                          kernel_size=2,\n",
        "                                                          strides=2)\n",
        "    def call(self, inputs, **kwargs):\n",
        "        x = self.upsampling(inputs)\n",
        "        x = self.residual(x)\n",
        "        return x\n",
        "  \n",
        "    \n",
        "class Ouput_layer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Output layer of model with shape (H,W,3)\n",
        "    \"\"\"\n",
        "    def __init__(self, trainable=True, **kwargs):\n",
        "        super(Ouput_layer, self).__init__(**kwargs)\n",
        "        self.conv2d = tf.keras.layers.Conv2D(filters=3,\n",
        "                                             kernel_size=3,\n",
        "                                             padding=\"same\")\n",
        "        self.bn2d = tf.keras.layers.BatchNormalization()\n",
        "    \n",
        "    def call(self, inputs, **kwargs):\n",
        "        output = self.conv2d(inputs)\n",
        "        output = self.bn2d(output)\n",
        "        output = tf.nn.relu(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcqy_LaWqrHY"
      },
      "outputs": [],
      "source": [
        "def Generator_model(shape=(256,256,3), train_attention=True):\n",
        "    x_input = keras.Input(shape, name=\"Input_layer\")\n",
        "\n",
        "    encoder0 = Residual_Block(num_filter=32, kernel_size=3, name=\"Encoder_0\")(x_input)\n",
        "    encoder0 = MaxPooling2D((2,2), name=\"MaxPooling2D_0\")(encoder0)\n",
        "\n",
        "    encoder1 = Residual_Block(num_filter=64, kernel_size=3, name=\"Encoder_1\")(encoder0)\n",
        "    encoder1 = MaxPooling2D((2,2), name=\"MaxPooling2D_1\")(encoder1)\n",
        "    \n",
        "    encoder2 = Residual_Block(num_filter=128, kernel_size=3, name=\"Encoder_2\")(encoder1)\n",
        "\n",
        "    #FENC\n",
        "    f_enc = spatial_attention(trainable=train_attention, name=\"F_enc\")(encoder2)\n",
        "\n",
        "    encoder2 = MaxPooling2D((2,2), name=\"MaxPooling2D_2\")(encoder2)\n",
        "\n",
        "    encoder3 = Residual_Block(num_filter=256, kernel_size=3, name=\"Encoder_3\")(encoder2)\n",
        "    encoder3 = MaxPooling2D((2,2), name=\"MaxPooling2D_3\")(encoder3)\n",
        "\n",
        "    encoder4 = Residual_Block(num_filter=512, kernel_size=3, name=\"Encoder_4\")(encoder3)\n",
        "    encoder4 = MaxPooling2D((2,2), name=\"MaxPooling2D_4\")(encoder4)\n",
        "\n",
        "    bottleneck = Conv2D(1024, 3, padding=\"same\", name=\"bottleneck\")(encoder4)\n",
        "\n",
        "    decoder0 = Decoder_Block(num_filter=512, kernel_size=3, name=\"Decoder_0\")(bottleneck)\n",
        "    decoder1 = Decoder_Block(num_filter=256, kernel_size=3, name=\"Decoder_1\")(decoder0)\n",
        "    decoder2 = Decoder_Block(num_filter=128, kernel_size=3, name=\"Decoder_2\")(decoder1)\n",
        "\n",
        "    #DEC \n",
        "    f_dec = spatial_attention(trainable=train_attention, name=\"F_dec\")(decoder2)\n",
        "    f_fused = compute_fused(f_enc,f_dec, trainable=train_attention, name_layer=\"Attention_map\")\n",
        "\n",
        "    # if(train_attention==True):\n",
        "    #     input_decoder3 = Add(name=\"Add_f_fused\")([decoder2, f_fused])\n",
        "    # elif(train_attention==False):\n",
        "    #     input_decoder3=decoder2\n",
        "\n",
        "    input_decoder3 = Add(name=\"Add_f_fused\")([decoder2, f_fused])\n",
        "\n",
        "    decoder3 = Decoder_Block(num_filter=64, kernel_size=3, name=\"Decoder_3\")(input_decoder3)\n",
        "    decoder4 = Decoder_Block(num_filter=32, kernel_size=3, name=\"Decoder_4\")(decoder3)\n",
        "\n",
        "    imageout = Ouput_layer(name=\"Ouput_layer\")(decoder4)\n",
        "\n",
        "    mymodel = Model(inputs = x_input, outputs = imageout, name = \"Generator\")\n",
        "    return mymodel \n",
        "\n",
        "generator = Generator_model(train_attention=True)\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUXVvfg_q4ma"
      },
      "source": [
        "# **Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnp4kt8dqs96"
      },
      "outputs": [],
      "source": [
        "def downsample(filters, size, apply_batchnorm=True):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "  if apply_batchnorm:\n",
        "    result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  result.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuX0u_x-q_kQ"
      },
      "outputs": [],
      "source": [
        "def Discriminator():\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
        "  tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n",
        "\n",
        "  x = tf.keras.layers.concatenate([inp, tar])  # (e, 256, 256, channels*2)batch_siz\n",
        "\n",
        "  down1 = downsample(64, 4, False)(x)  # (batch_size, 128, 128, 64)\n",
        "  down2 = downsample(128, 4)(down1)  # (batch_size, 64, 64, 128)\n",
        "  down3 = downsample(256, 4)(down2)  # (batch_size, 32, 32, 256)\n",
        "\n",
        "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (batch_size, 34, 34, 256)\n",
        "  conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
        "                                kernel_initializer=initializer,\n",
        "                                use_bias=False)(zero_pad1)  # (batch_size, 31, 31, 512)\n",
        "\n",
        "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
        "\n",
        "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
        "\n",
        "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 33, 33, 512)\n",
        "\n",
        "  last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
        "                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 30, 30, 1)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inp, tar], outputs=last)\n",
        "\n",
        "discriminator = Discriminator()\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuSSgpJRrC54"
      },
      "source": [
        "# **Config Loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEvqFCz2rAp8"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.1)\n",
        "mae = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)\n",
        "\n",
        "def discriminator_loss(real_image, fake_image):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_image), real_image)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_image), fake_image)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwDrOyPLrLXG"
      },
      "outputs": [],
      "source": [
        "def loss_SSIM(target_image, gen_image):\n",
        "    ssim = tf.image.ssim(target_image, gen_image, max_val=1.0, filter_size=11,\n",
        "                          filter_sigma=1.5, k1=0.01, k2=0.03)\n",
        "    return (1-ssim)\n",
        "\n",
        "\n",
        "def generator_loss(target_image, gen_image):\n",
        "    #Loss SSIM\n",
        "    l_ssim = tf.reduce_mean(loss_SSIM(target_image, gen_image))\n",
        "\n",
        "    #Loss Recontruction\n",
        "    #l_rec = tf.reduce_mean(tf.abs(target_image - gen_image))\n",
        "    l_rec = mae(target_image, gen_image)\n",
        "    return l_ssim, l_rec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhGygL_crRL_"
      },
      "source": [
        "# **Train Step**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9FZmueXrNZm"
      },
      "outputs": [],
      "source": [
        "!mkdir path_to_save_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUwNt5GFrVmt"
      },
      "outputs": [],
      "source": [
        "#Config optimizers and learning rate\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-5, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(9e-6, beta_1=0.5)\n",
        "\n",
        "lambda_rec = 1.2\n",
        "lambda_adv = 0.5\n",
        "lambda_ssim = 80\n",
        "lambda_mask = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Esqp_wR7rcSA"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = path_to_checkpoint\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n",
        "log_dir=\"logs/\"\n",
        "\n",
        "summary_writer = tf.summary.create_file_writer(\n",
        "  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_JvDwXsrkMd"
      },
      "outputs": [],
      "source": [
        "def evaluate_val(valid_dataset):\n",
        "    loss_total_each_batch=[]\n",
        "    loss_ssim_each_batch=[]\n",
        "    loss_rec_each_batch=[]\n",
        "    disc_loss_each_batch=[]\n",
        "    for step, (batch_test_image, batch_test_target) in enumerate(valid_dataset):\n",
        "        valid_out = generator(batch_test_image, training=True)\n",
        "        val_ssim_loss,  val_rec_loss = generator_loss(batch_test_target, valid_out)\n",
        "        loss_ssim_each_batch.append(val_ssim_loss)\n",
        "        loss_rec_each_batch.append(val_rec_loss)\n",
        "\n",
        "        disc_real_output  = discriminator([batch_test_image, batch_test_target], training=True)\n",
        "        disc_generated_output  = discriminator([batch_test_image, valid_out], training=True)\n",
        "\n",
        "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "        loss_total = lambda_rec*val_rec_loss + lambda_adv*disc_loss + lambda_ssim*val_ssim_loss\n",
        "\n",
        "        loss_total_each_batch.append(loss_total)\n",
        "        disc_loss_each_batch.append(disc_loss)\n",
        "        \n",
        "    return np.mean(loss_total_each_batch), np.mean(loss_ssim_each_batch), np.mean(loss_rec_each_batch), np.mean(disc_loss_each_batch)\n",
        "\n",
        "\n",
        "def train_step(train_datasets, update_D):\n",
        "    loss_total_each_batch=[]\n",
        "    loss_ssim_each_batch=[]\n",
        "    loss_rec_each_batch=[]\n",
        "    disc_loss_each_batch=[]\n",
        "\n",
        "    for step, (batch_train_image, batch_train_target) in enumerate(train_datasets):\n",
        "        print(f\"Batch: {step+1}...\", end='\\r')\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            gen_out = generator(batch_train_image, training=True)\n",
        "            gen_ssim_loss,  gen_rec_loss = generator_loss(batch_train_target, gen_out)\n",
        "            loss_ssim_each_batch.append(gen_ssim_loss)\n",
        "            loss_rec_each_batch.append(gen_rec_loss)\n",
        "\n",
        "            disc_real_output = discriminator([batch_train_image, batch_train_target], training=True)\n",
        "            disc_generated_output = discriminator([batch_train_image, gen_out], training=True)\n",
        "\n",
        "            disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "            loss_total = lambda_rec*gen_rec_loss + lambda_adv*disc_loss + lambda_ssim*gen_ssim_loss\n",
        "\n",
        "            loss_total_each_batch.append(loss_total)\n",
        "            disc_loss_each_batch.append(disc_loss)\n",
        "\n",
        "        generator_gradients = gen_tape.gradient(loss_total,\n",
        "                                    generator.trainable_variables)\n",
        "        generator_optimizer.apply_gradients(zip(generator_gradients,\n",
        "                                        generator.trainable_variables))\n",
        "    \n",
        "        if update_D:\n",
        "            discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "                                                discriminator.trainable_variables)\n",
        "            discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
        "                                                discriminator.trainable_variables))\n",
        "            \n",
        "    return np.mean(loss_total_each_batch), np.mean(loss_ssim_each_batch), np.mean(loss_rec_each_batch), np.mean(disc_loss_each_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPzci9wMrwae"
      },
      "outputs": [],
      "source": [
        "def model_fit(train_datasets, test_datasets, epochs, num_epoch_update_D):\n",
        "    history_train = {\"loss_total\": [],\n",
        "                      \"loss_ssim\": [],\n",
        "                      \"loss_rec\": [], \n",
        "                      \"loss_disc\":[]}\n",
        "    \n",
        "    history_val = {\"loss_total\": [],\n",
        "                   \"loss_ssim\": [],\n",
        "                   \"loss_rec\": [], \n",
        "                   \"loss_disc\":[]}\n",
        "    count=0\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        \n",
        "        #Training\n",
        "        if epoch%num_epoch_update_D==0:\n",
        "            update_D = True\n",
        "            \n",
        "        if epoch==0:\n",
        "            update_D=False\n",
        "            print(f\"\\nEpoch {epoch+1}/{epochs}\\nOny Update G!\")\n",
        "\n",
        "        else:\n",
        "            if epoch%num_epoch_update_D==0:\n",
        "                update_D = True\n",
        "                print(f\"\\nEpoch {epoch+1}/{epochs}:\\nUpdate D!\")\n",
        "\n",
        "            else:\n",
        "                update_D = False\n",
        "                print(f\"\\nEpoch {epoch+1}/{epochs}\\nOny Update G!\")\n",
        "\n",
        "        train_loss_total, train_ssim, train_rec, train_disc = train_step(train_datasets, epoch, update_D)\n",
        "\n",
        "        history_train[\"loss_total\"].append(train_loss_total) \n",
        "        history_train[\"loss_ssim\"].append(train_ssim)\n",
        "        history_train[\"loss_rec\"].append(train_rec) \n",
        "        history_train[\"loss_disc\"].append(train_disc) \n",
        "\n",
        "        #Evaluation on testsets\n",
        "        val_total, val_ssim, val_rec, val_disc = evaluate_val(test_datasets)\n",
        "        \n",
        "        history_val[\"loss_total\"].append(val_total) \n",
        "        history_val[\"loss_ssim\"].append(val_ssim)\n",
        "        history_val[\"loss_rec\"].append(val_rec)\n",
        "        history_val[\"loss_disc\"].append(val_disc)\n",
        "\n",
        "        print(f\"  loss_total: {train_loss_total} - loss_ssim: {train_ssim} - loss_rec: {train_rec} - loss_discriminator: {train_disc}\")\n",
        "        print(f\"  val_loss: {val_total} - val_ssim: {val_ssim} - val_rec: {val_rec} - val_Disc: {val_disc}\")\n",
        "        print(\"  Time taken: %.2fs\" % (time.time() - start_time))\n",
        "        \n",
        "        if history_val[\"loss_total\"][epoch] <= min(history_val[\"loss_total\"]) :\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix) \n",
        "            \n",
        "        if epoch%2==0:\n",
        "            for input, target in test_datasets.take(1):\n",
        "                generate_images(generator, input, target)\n",
        "            \n",
        "    plt.plot(history_train['loss_total'])\n",
        "    plt.plot(history_val['loss_total'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOrOkCcTr-yn"
      },
      "source": [
        "# **Train model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9otRZVfKr-f4"
      },
      "outputs": [],
      "source": [
        "epochs = 150\n",
        "num_epoch_update_D = 15\n",
        "model_fit(train_datasets, test_datasets, epochs, num_epoch_update_D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buHmdnLRsNka"
      },
      "source": [
        "## Test model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "generator.save('generator.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKh_3WkOsS5_"
      },
      "outputs": [],
      "source": [
        "status = generator.load_weights(\"generator.h5\", by_name=True)\n",
        "for input, target in test_datasets.take(1):\n",
        "    generate_images(generator, input, target)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
